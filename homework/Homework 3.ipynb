{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Problem 1: Hamiltonian Truncation of the Anharmonic Oscillator\n",
                "\n",
                "This is a grad class! It means that I have the luxury of assigning homework problems that go beyond things we've done in class so that you can learn something awesome. In this case we'll study a famous model, the anharmonic oscillator \n",
                "\n",
                "$$ H = \\frac{p^2}{2m} + \\frac{1}{2} m \\omega^2 x^2 + \\lambda x^4 $$\n",
                "\n",
                "which is a classic problem in perturbation theory. But we will not use perturbation theory! Instead we will use the Hamiltonian truncation method, which is a numerical method that is exact in the limit of an infinite basis. This allows us to do the calculation at strong coupling where perturbation theory fails, e.g. outside the $\\lambda \\ll 1$ regime. For simplicity, let's set $\\hbar = \\omega = m = 1$.\n",
                "\n",
                "1. Write a code that computes the Hamiltonian in the eigenbasis of the harmonic oscillator. Recall that this is the $\\lambda=0$ case, and the $\\lambda=0$ Hamiltonian may be written as \n",
                "    $$H = (N+\\frac12)$$\n",
                "    where I have again set the constants to $1$ and $N$ is the number operator, $N=a^\\dagger a$. If this is unfamiliar, look up any quantum mechanics textbook for the relationship between $x$, $p$, $a^\\dagger$, and $a$. Since this is an infinite Hamiltonian, you'll have to truncate it somewhere. Let that parameter be $N_t$, so that your $H$ is an $N_t\\times N_t$ matrix. \n",
                "2. For $N_t \\in \\{20,21,\\dots 80\\}$ compute the first 10 eigenvalues for $\\lambda \\in \\{0,.1,1.,10\\}$ and plot them (in a grid using `plt.subplots`) as a function of $N_t$, one plot for each lambda. Feel free to use `scipy.linalg.eigh` to compute the eigensystem. What features do you notice in the spectrum? Why is that interesting?\n",
                "3. For $N_t=80$, consider `lams = [.5, 1., 2., 4., 8., 16., 32., 64.]` and find the functional dependence of the ground state energy on $\\lambda$.\n",
                "4. For $N_t=80$ and the $10th$ eigenstate, study $\\Delta x = \\sqrt{\\langle x^2\\rangle}$ and $\\Delta p = \\sqrt{\\langle p^2\\rangle}$. Plot $\\Delta x$, $\\Delta p$, and their product as a function of $\\lambda$ to demonstrate the uncertainty principle."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Problem 2: Metropolis Analysis\n",
                "\n",
                "We would like to probe the Metropolis algorithm to make sure it's doing what we think it is.\n",
                "\n",
                "1. **Convergence.** The claim is that the Metropolis algorithm gives samples from a desired distribution. We saw this with our naked eye, but in scientific applications where we can't meaningfully eyeball the distribution we need a formal measure of convergence to the desired distribution. For that, we'll use the Kullback-Leibler divergence\n",
                "    $$D_{KL}(P||Q) = \\sum_i P(i) \\log \\frac{P(i)}{Q(i)}$$\n",
                "    which has the property that $D_{KL}(P||Q) \\geq 0$ with equality if and only if $P=Q$.  \n",
                "    \n",
                "    For\n",
                "    $\\delta \\in$\n",
                "    `[2**k for k in range(-4,4)]`\n",
                "    adapt the Gaussian code from class to compute the Kullback-Leibler divergence between the distribution of samples from the Metropolis algorithm and the Gaussian.  Write a code to compute (without using a stats library\ud83d\ude09) and plot the Kullback-Leibler divergence as a function of $\\delta$ (display your results nicely in a grid using `plt.subplots`) and determine the functional dependence of the Kullback-Leibler divergence on $\\delta$ (e.g., linear, exponential, polynomial, etc). Fit that dependence accordingly, numerically (here, feel free to use `scipy.curve_fit`). **Hint: The histogram output from pyplot can be used to easy compute bin centers and probabilities of the data generated by Metropolis.** \n",
                "\n",
                "2. **Acceptance.** Analyze the acceptance ratio in terms of $\\delta$. Plot and determine the functional dependence of the acceptance ratio on $\\delta$. Fit that dependence accordingly, numerically.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Problem 3: Integration Examples\n",
                "It's good to get more practice with Monte Carlo integration and importance sampling, so you feel it a bit more strongly in your bones.  Here are some examples to try.\n",
                "1. Calculate the integral $\\int_0^1 x^2 dx=1/3$ using simple MC integration and importance sampling with $P(x)=x$.\n",
                "2. Calculate the integral $\\int_0^1 \\sqrt{x}dx=2/3$ using simple MC integration and $P(x)=1-e^{-ax}$. Find the values of $a$ that minimizes the variance.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Problem 4: Bouncing Around the Room\n",
                "Consider the 2d Schrodinger problem we did in class, but consider instead the potential\n",
                "$$V(x,y) = C$$\n",
                "for $r > 1$, otherwise zero. This is the radial finite potential well.\n",
                "1. Write a code to start the Gaussian wavepacket from class at $(x,y) = (0.5,0)$ and momentum $kx=0$ but momentum $ky$ some non-zero reasonable value.\n",
                "2. Study the dyanmics for a long enough period of time for there to be interesting behavior. What do you see? Demonstrate in plots that the value of $C$ affects the amount of tunneling into the barrier by calculating the transmission coefficient, $T$."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "COMP",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}